{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzTyg_-1tgJk"
      },
      "source": [
        "# Behzad Shomali, Ilaha Manafova\n",
        "### Exercise Group F\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pykq4CkrHRYg"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4tZQP8txL-Wz"
      },
      "outputs": [],
      "source": [
        "def parse_training_data(path):\n",
        "    with open(path, 'r') as file:\n",
        "        line = file.readline().strip()\n",
        "        line_counter = 0\n",
        "        while line:\n",
        "            line_counter += 1\n",
        "\n",
        "            if line_counter == 2: # the line contains the values of P, N, M\n",
        "                line = line[1:] # skip the # sign at the beginning of the line\n",
        "                line_segments = line.split(' ')\n",
        "                for segment in line_segments:\n",
        "                    segment = segment.strip()\n",
        "                    if segment != '':\n",
        "                        if segment[0] == 'P': # P=<P_VALUE>\n",
        "                            P = int(segment[2:])\n",
        "                        elif segment[0] == 'N': # N=<N_VALUE>\n",
        "                            N = int(segment[2:])\n",
        "                        elif segment[0] == 'M': # M=<M_VALUE>\n",
        "                            M = int(segment[2:])\n",
        "                \n",
        "                X_train = np.empty((P, N))\n",
        "                Y_train = np.empty((P, M))\n",
        "            \n",
        "            elif line_counter >= 3: # contains training data as well as desired output starting at line 3\n",
        "                # line_segments would be smth. like:\n",
        "                # ['1.0', '1.0', '1.0', '0.9']\n",
        "                # where the first N items are the values\n",
        "                # for input data dimensions and the\n",
        "                # last M items are the last layer's\n",
        "                # outputs\n",
        "\n",
        "                line_segments = line.split(' ')\n",
        "                line_segments = list(filter(lambda seg: seg != '', line_segments))\n",
        "                X_train[line_counter-3] = np.asarray(list(map(float, line_segments[:N])))\n",
        "                Y_train[line_counter-3] = np.asarray(list(map(float, line_segments[-M:])))\n",
        "                \n",
        "            line = file.readline().strip()\n",
        "    \n",
        "    return P, N, M, X_train, Y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ITS6vvHqI5kc"
      },
      "outputs": [],
      "source": [
        "def tanh(z):\n",
        "    return (np.exp(z)-np.exp(-z)) / (np.exp(z)+np.exp(-z))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uNz4a_xpfZ6j"
      },
      "outputs": [],
      "source": [
        "def tanh_derivative(z):\n",
        "    return 1 - tanh(z)**2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iE8zSiF5JTjA"
      },
      "outputs": [],
      "source": [
        "def logistic(z):\n",
        "    return 1/(1+np.exp(-z))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oxJAfuTafxtX"
      },
      "outputs": [],
      "source": [
        "def logistic_derivative(z):\n",
        "    f = logistic(z)\n",
        "    return  f * (1-f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OenWuuwfJhYx"
      },
      "outputs": [],
      "source": [
        "def identity(z):\n",
        "    return z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mpqBnDLpf_L_"
      },
      "outputs": [],
      "source": [
        "def identity_derivative(z):\n",
        "    return np.ones_like(z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXqphTOqJj-x"
      },
      "outputs": [],
      "source": [
        "def initilization(\n",
        "    layers_num, # number of layers including input and output layer\n",
        "    layers_neurons, # number of neurons per layer, represented in a list [l1_neurons, l2_neurons, ...] \n",
        "    layers_transfer_functions, # transfer function used for each layer, represented in a list [l1_transferFunc, l2_transferFunc, ...] \n",
        "    layers_lr, # learning rate used for each layer, represented in a list [l1_lr, l2_lr, ...] \n",
        "    random_seed=None # if random_seed is not specified, then it is set randomly\n",
        "):\n",
        "    '''\n",
        "    Intialize a network based on the specified params\n",
        "    User can set the number of layers, number of neurons \n",
        "    of a layer, and also use different transfer functions\n",
        "    and learning rates for different layers.\n",
        "\n",
        "    The network is implemented in the format of dictionaries,\n",
        "    such that the information of each layer and weights can \n",
        "    be accessed simply\n",
        "    '''\n",
        "    if random_seed is not None:\n",
        "        np.random.rand(random_seed)\n",
        "\n",
        "    network = {}\n",
        "    network['layers_num'] = layers_num\n",
        "    \n",
        "    for layer in range(layers_num):\n",
        "        network[f'layer_{layer}'] = {}\n",
        "        network[f'layer_{layer}']['neurons'] = layers_neurons[layer]\n",
        "        network[f'layer_{layer}']['lr'] = layers_lr[layer]\n",
        "        \n",
        "        if layers_transfer_functions[layer] == 'tanh':\n",
        "            network[f'layer_{layer}']['transfer_function'] = tanh\n",
        "            network[f'layer_{layer}']['transfer_derivative'] = tanh_derivative\n",
        "        elif layers_transfer_functions[layer] == 'logistic':\n",
        "            network[f'layer_{layer}']['transfer_function'] = logistic\n",
        "            network[f'layer_{layer}']['transfer_derivative'] = logistic_derivative\n",
        "        else: # identity\n",
        "            network[f'layer_{layer}']['transfer_function'] = identity\n",
        "            network[f'layer_{layer}']['transfer_derivative'] = identity_derivative\n",
        "\n",
        "        if layer > 0: \n",
        "            # network['w_hk']: indicates the weights/connections\n",
        "            # that connect layer h to layer k        \n",
        "            weights = np.random.random((layers_neurons[layer-1], layers_neurons[layer])) # shape: (prev_neurons, cur_neurons) 0 <=weights <=1\n",
        "            weights *= 4 # 0 <= weights <= 4\n",
        "            weights -= 2 # -2 <= weights <= 2\n",
        "            network[f'w_{layer-1}{layer}'] = weights\n",
        "\n",
        "    return network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ue0rsRaGLU1K"
      },
      "outputs": [],
      "source": [
        "def feed_forward(network, X):\n",
        "    net = {} # keeps the weighted sum of inputs for current layer\n",
        "    out = {} # keeps transfer_func(net)\n",
        "    for layer in range(network['layers_num']-1):\n",
        "        transfer_func = network[f'layer_{layer}']['transfer_function']\n",
        "        \n",
        "        if layer == 0: # input layer\n",
        "            net[f'layer_{layer}'] = X.dot(network[f'w_{layer}{layer+1}'])\n",
        "            out[f'layer_{layer}'] = transfer_func(net[f'layer_{layer}'])\n",
        "        else: \n",
        "            net[f'layer_{layer}'] = out[f'layer_{layer-1}'].dot(network[f'w_{layer}{layer+1}'])\n",
        "            out[f'layer_{layer}'] = transfer_func(net[f'layer_{layer}'])\n",
        "    return net, out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgh8EeoqfHLb"
      },
      "outputs": [],
      "source": [
        "def backpropagation(X, net, out, label):\n",
        "    output_dim = label.shape[0]\n",
        "    delta = {} # simply keeps delta for each layer's neurons\n",
        "    \n",
        "    # iterate layers from output layer to \n",
        "    # backward to backpropagte the error\n",
        "    for layer in range(network[\"layers_num\"]-1, -1, -1): \n",
        "        transfer_func_deriv = network[f'layer_{layer}']['transfer_derivative']\n",
        "        delta[f'layer_{layer}'] = []\n",
        "        \n",
        "        if layer == network[\"layers_num\"]-1: # output layer\n",
        "            delta_output = (label-out[f'layer_{layer-1}']) * (transfer_func_deriv(out[f'layer_{layer-1}']))\n",
        "            delta[f'layer_{layer}'] = delta_output\n",
        "\n",
        "        elif layer >= 1: # hidden layer\n",
        "            for h in range(network[f'layer_{layer}']['neurons']): # iterate over layer's neurons\n",
        "                weight = network[f'w_{layer}{layer+1}'][h] # shape: neurons[layer+1]\n",
        "                delta_h = (delta[f'layer_{layer+1}'].squeeze().dot(weight))*(transfer_func_deriv(out[f'layer_{layer-1}']))[h]\n",
        "                delta[f'layer_{layer}'].append(delta_h)\n",
        "            delta[f'layer_{layer}'] = np.vstack(delta[f'layer_{layer}']).squeeze()\n",
        "        \n",
        "        else:\n",
        "            for h in range(network[f'layer_{layer}']['neurons']): # iterate over layer's neurons\n",
        "                weight = network[f'w_{layer}{layer+1}'][h]\n",
        "                delta_h = delta[f'layer_{layer+1}'].squeeze().dot(weight)* (X)[h]\n",
        "                delta[f'layer_{layer}'].append(delta_h)\n",
        "            delta[f'layer_{layer}'] = np.vstack(delta[f'layer_{layer}']).squeeze()\n",
        "\n",
        "    return delta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5KVklJ3wijD"
      },
      "outputs": [],
      "source": [
        "def update(network, layer_delta, out, X):\n",
        "    for layer in range(network['layers_num']-1):\n",
        "        lr = network[f'layer_{layer}']['lr']\n",
        "        for i in range(network[f'layer_{layer}']['neurons']):\n",
        "            for j in range(network[f'layer_{layer+1}']['neurons']):\n",
        "                if layer == 0: # input layer\n",
        "                    network[f'w_{layer}{layer+1}'][i,j] += lr*layer_delta[f'layer_{layer+1}'][j]*X[i]\n",
        "                else: # hidden/output layer\n",
        "                    network[f'w_{layer}{layer+1}'][i,j] += lr*layer_delta[f'layer_{layer+1}'][j]*out[f'layer_{layer-1}'][i]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AMh7WSG8YI0z"
      },
      "outputs": [],
      "source": [
        "def error_function(out, label):\n",
        "    output = out[f'layer_{network[\"layers_num\"]-2}']\n",
        "    errors = (output-label) ** 2 # shape: P*M\n",
        "    cumulative_error = np.sum(errors, axis=0) # shape: 1*M this is only be useful when wh perform batch(cumulative) learning\n",
        "\n",
        "    return cumulative_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2RY1d-oQCJ4"
      },
      "outputs": [],
      "source": [
        "path = '/content/data/PA-B_training_data_04.txt'\n",
        "P, input_dim, output_dim, X_train, Y_train = parse_training_data(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLRfF1FSHU9U"
      },
      "outputs": [],
      "source": [
        "layers_num = 4\n",
        "layers_neurons = [input_dim, 16, 8, output_dim]\n",
        "layers_transfer_functions = ['tanh', 'tanh', 'tanh', 'tanh']\n",
        "layers_lr = [5e-3, 5e-3, 1e-3, 1e-4]\n",
        "iterations = 500"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5YevknKoLA2x"
      },
      "outputs": [],
      "source": [
        "network = initilization(\n",
        "    layers_num, \n",
        "    layers_neurons, \n",
        "    layers_transfer_functions,\n",
        "    layers_lr, \n",
        "    random_seed=2000\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ib0C3kCEYVGM",
        "outputId": "bdb25340-f441-443b-8af3-fb5fc20de282"
      },
      "outputs": [],
      "source": [
        "global_error = []\n",
        "for iter in range(iterations):  \n",
        "    error = 0\n",
        "    for i in range(X_train.shape[0]):\n",
        "        X = X_train[i]\n",
        "        Y = Y_train[i]\n",
        "        net, out = feed_forward(network, X)\n",
        "        error += np.mean(error_function(out, Y))/len(X)\n",
        "        layer_delta = backpropagation(X, net, out, Y)\n",
        "        update(network, layer_delta, out, X)\n",
        "    global_error.append(error)\n",
        "    \n",
        "    if iter % int(iterations/25) == 0:\n",
        "        print(f'Iteration: {iter:3d}/ Error: {error:.4f}')\n",
        "\n",
        "with open(f'./learning_curve_{path.split(\"/\")[-1]}', 'w') as f:\n",
        "    for error in global_error:\n",
        "        f.write(f\"{error}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "afXqjpgnKqo8",
        "outputId": "84c94145-b158-4548-f010-c70c1bd3183a"
      },
      "outputs": [],
      "source": [
        "plt.rcParams['figure.figsize'] = (10,6)\n",
        "fig, ax = plt.subplots(2, 2, sharex=True)\n",
        "\n",
        "for i in range(2):\n",
        "    for j in range(2):\n",
        "        file_suffix = f'{2*(i)+(j+1)}'\n",
        "        errors_list = []\n",
        "        with open(f'learning_curve_PA-B_training_data_0{2*(i)+(j+1)}.txt', 'r') as f:\n",
        "            line = f.readline()\n",
        "            while line:\n",
        "                errors_list.append(float(line))\n",
        "                line = f.readline()\n",
        "        \n",
        "        ax[i][j].plot(errors_list)\n",
        "        ax[i][j].set_title(f'Learning curve for training_data_{file_suffix}')\n",
        "        if i == 1:\n",
        "            ax[i][j].set_xlabel('Iterations')\n",
        "        if j == 0:\n",
        "            ax[i][j].set_ylabel('Error')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "fe22a7749f68daf798cadcb67369487b7f36e883059582304c2ca8b411379149"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
